

import gradio as gr
import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification
from huggingface_hub import snapshot_download
from tqdm.auto import tqdm

print("ğŸ“¥ Model indiriliyor...")

model_name = "Raxus-99/huffpost-model"

# Model dosyalarÄ±nÄ± ilerleme Ã§ubuÄŸu ile indir
model_path = snapshot_download(
    repo_id=model_name,
    local_dir="./huffpost_model_local",
    resume_download=True,
    tqdm_class=tqdm
)

print("âœ… Ä°ndirme tamamlandÄ±!")
print("ğŸ“¦ Model yÃ¼kleniyor...")

tokenizer = AutoTokenizer.from_pretrained(model_path)
print("âœ… Tokenizer yÃ¼klendi")

model = AutoModelForSequenceClassification.from_pretrained(model_path)
print("âœ… Model yÃ¼klendi")


def predict(headline, description):
    text = f"{headline} {description}".strip()
    inputs = tokenizer(text, return_tensors='pt', truncation=True, max_length=128, padding=True)

    model.eval()
    with torch.no_grad():
        outputs = model(**inputs)

    probs = torch.nn.functional.softmax(outputs.logits, dim=-1)[0]
    top5 = torch.topk(probs, k=5)

    results = {}
    for idx, prob in zip(top5.indices, top5.values):
        results[model.config.id2label[idx.item()]] = float(prob.item())

    return results


print("ğŸš€ ArayÃ¼z baÅŸlatÄ±lÄ±yor...")

demo = gr.Interface(
    fn=predict,
    inputs=[
        gr.Textbox(label="Haber BaÅŸlÄ±ÄŸÄ±", placeholder="Ã–rn: Trump Announces New Policy"),
        gr.Textbox(label="AÃ§Ä±klama (opsiyonel)", placeholder="KÄ±sa aÃ§Ä±klama")
    ],
    outputs=gr.Label(label="Tahmin SonuÃ§larÄ±", num_top_classes=5),
    title="ğŸ“° Haber Kategori SÄ±nÄ±flandÄ±rÄ±cÄ±",
    description="BERT ile eÄŸitilmiÅŸ HuffPost haber sÄ±nÄ±flandÄ±rÄ±cÄ±",
    examples=[
        ["Trump Announces New Policy", ""],
        ["Best Travel Destinations", ""],
    ]
)

demo.launch(share=True)