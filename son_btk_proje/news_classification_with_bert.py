# 1. Kurulum
#!pip install transformers datasets accelerate matplotlib seaborn - q

import json
import pandas as pd
import numpy as np
import torch
import matplotlib.pyplot as plt
import seaborn as sns
from transformers import (
    AutoTokenizer,
    AutoModelForSequenceClassification,
    TrainingArguments,
    Trainer,
    TrainerCallback
)
from datasets import Dataset
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix
from collections import defaultdict

# 2. Veri Setini YÃ¼kleyin
print("ğŸ“‚ Veri yÃ¼kleniyor...")

data = []
with open('/kaggle/input/data-set/News_Category_Dataset_v3.json', 'r', encoding='utf-8') as f:
    for line in f:
        data.append(json.loads(line))

df = pd.DataFrame(data)

print(f"âœ… Toplam {len(df)} haber yÃ¼klendi")

# 3. Veri Ä°nceleme ve HazÄ±rlÄ±k
df['text'] = df['headline'] + " " + df['short_description']
df = df[['text', 'category']]
df = df.rename(columns={'category': 'label'})
df = df.dropna()

print(f"\nâœ… {len(df)} temiz Ã¶rnek hazÄ±r")

# 4. Label Encoding
label2id = {label: idx for idx, label in enumerate(sorted(df['label'].unique()))}
id2label = {idx: label for label, idx in label2id.items()}

print(f"\nğŸ·ï¸  {len(label2id)} kategori")

df['label'] = df['label'].map(label2id)

# 5. Train/Test Split
train_df, test_df = train_test_split(
    df,
    test_size=0.15,
    random_state=42,
    stratify=df['label']
)

print(f"\nğŸ“š Train: {len(train_df)} | Test: {len(test_df)}")

# 6. Dataset OluÅŸturma
train_dataset = Dataset.from_pandas(train_df[['text', 'label']].reset_index(drop=True))
test_dataset = Dataset.from_pandas(test_df[['text', 'label']].reset_index(drop=True))

# 7. Tokenization
print("\nğŸ”¤ Tokenization baÅŸlÄ±yor...")
model_name = "bert-base-uncased"
tokenizer = AutoTokenizer.from_pretrained(model_name)


def tokenize_function(examples):
    return tokenizer(
        examples['text'],
        padding='max_length',
        truncation=True,
        max_length=128
    )


train_dataset = train_dataset.map(tokenize_function, batched=True, remove_columns=['text'])
test_dataset = test_dataset.map(tokenize_function, batched=True, remove_columns=['text'])

print("âœ… Tokenization tamamlandÄ±")

# 8. Model YÃ¼kleme
print("\nğŸ¤– Model yÃ¼kleniyor...")
num_labels = len(label2id)

model = AutoModelForSequenceClassification.from_pretrained(
    model_name,
    num_labels=num_labels,
    id2label=id2label,
    label2id=label2id
)

print(f"âœ… Model hazÄ±r - {num_labels} kategorili sÄ±nÄ±flandÄ±rma")


# 9. EÄŸitim GeÃ§miÅŸi iÃ§in Callback
class MetricsCallback(TrainerCallback):
    def __init__(self):
        self.metrics = defaultdict(list)

    def on_log(self, args, state, control, logs=None, **kwargs):
        if logs:
            for key, value in logs.items():
                self.metrics[key].append(value)


metrics_callback = MetricsCallback()


# 10. Metrik Hesaplama
def compute_metrics(eval_pred):
    predictions, labels = eval_pred
    predictions = np.argmax(predictions, axis=1)

    accuracy = accuracy_score(labels, predictions)
    f1 = f1_score(labels, predictions, average='weighted')

    return {
        'accuracy': accuracy,
        'f1': f1
    }


# 11. Training Arguments
training_args = TrainingArguments(
    output_dir='./results',
    num_train_epochs=3,
    per_device_train_batch_size=32,
    per_device_eval_batch_size=32,
    learning_rate=2e-5,
    weight_decay=0.01,
    eval_strategy='epoch',
    save_strategy='epoch',
    load_best_model_at_end=True,
    logging_steps=500,
    logging_dir='./logs',
    report_to='none',
    fp16=True,
)

# 12. Trainer
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=test_dataset,
    compute_metrics=compute_metrics,
    callbacks=[metrics_callback]
)

# 13. EÄŸitim
print("\nğŸš€ EÄŸitim baÅŸlÄ±yor...\n")
print("=" * 60)

trainer.train()

# 14. Model Kaydetme
model.save_pretrained('./huffpost_news_classifier')
tokenizer.save_pretrained('./huffpost_news_classifier')

with open('./huffpost_news_classifier/label_mapping.json', 'w') as f:
    json.dump({'label2id': label2id, 'id2label': {int(k): v for k, v in id2label.items()}}, f)

print("\nâœ… Model kaydedildi")

# ============================================
# RAPOR OLUÅTURMA
# ============================================

print("\n" + "=" * 60)
print("ğŸ“Š DETAYLI PERFORMANS RAPORU OLUÅTURULUYOR")
print("=" * 60)

# 1. EÄŸitim GeÃ§miÅŸi GrafiÄŸi
print("\nğŸ“ˆ 1. EÄŸitim grafiÄŸi oluÅŸturuluyor...")

fig, axes = plt.subplots(1, 2, figsize=(15, 5))

# Loss grafiÄŸi
train_loss = [log for log in trainer.state.log_history if 'loss' in log]
eval_loss = [log for log in trainer.state.log_history if 'eval_loss' in log]

axes[0].plot([log['epoch'] for log in train_loss], [log['loss'] for log in train_loss], label='Train Loss', marker='o')
axes[0].plot([log['epoch'] for log in eval_loss], [log['eval_loss'] for log in eval_loss], label='Validation Loss',
             marker='s')
axes[0].set_xlabel('Epoch')
axes[0].set_ylabel('Loss')
axes[0].set_title('Training & Validation Loss')
axes[0].legend()
axes[0].grid(True)

# Accuracy grafiÄŸi
eval_acc = [log for log in trainer.state.log_history if 'eval_accuracy' in log]
axes[1].plot([log['epoch'] for log in eval_acc], [log['eval_accuracy'] for log in eval_acc],
             label='Validation Accuracy', marker='s', color='green')
axes[1].set_xlabel('Epoch')
axes[1].set_ylabel('Accuracy')
axes[1].set_title('Validation Accuracy')
axes[1].legend()
axes[1].grid(True)

plt.tight_layout()
plt.savefig('training_history.png', dpi=300, bbox_inches='tight')
print("âœ… Grafik kaydedildi: training_history.png")

# 2. Test Seti DeÄŸerlendirme
print("\nğŸ“Š 2. Test seti deÄŸerlendirmesi...")

predictions = trainer.predict(test_dataset)
preds = np.argmax(predictions.predictions, axis=1)
true_labels = test_dataset['label']

# Confusion Matrix
print("\nğŸ” 3. Confusion matrix oluÅŸturuluyor...")

cm = confusion_matrix(true_labels, preds)

plt.figure(figsize=(20, 16))
sns.heatmap(cm, annot=False, fmt='d', cmap='Blues',
            xticklabels=[id2label[i] for i in sorted(id2label.keys())],
            yticklabels=[id2label[i] for i in sorted(id2label.keys())])
plt.title('Confusion Matrix', fontsize=16)
plt.ylabel('GerÃ§ek Kategori', fontsize=12)
plt.xlabel('Tahmin Edilen Kategori', fontsize=12)
plt.xticks(rotation=90)
plt.yticks(rotation=0)
plt.tight_layout()
plt.savefig('confusion_matrix.png', dpi=300, bbox_inches='tight')
print("âœ… Confusion matrix kaydedildi: confusion_matrix.png")

# 3. Kategori BaÅŸÄ±na Performans
print("\nğŸ“ˆ 4. Kategori bazlÄ± analiz...")

report = classification_report(
    true_labels,
    preds,
    target_names=[id2label[i] for i in sorted(id2label.keys())],
    digits=4,
    output_dict=True
)

# DataFrame oluÅŸtur
categories_df = pd.DataFrame({
    'Category': [cat for cat in report.keys() if cat not in ['accuracy', 'macro avg', 'weighted avg']],
    'Precision': [report[cat]['precision'] for cat in report.keys() if
                  cat not in ['accuracy', 'macro avg', 'weighted avg']],
    'Recall': [report[cat]['recall'] for cat in report.keys() if cat not in ['accuracy', 'macro avg', 'weighted avg']],
    'F1-Score': [report[cat]['f1-score'] for cat in report.keys() if
                 cat not in ['accuracy', 'macro avg', 'weighted avg']],
    'Support': [report[cat]['support'] for cat in report.keys() if cat not in ['accuracy', 'macro avg', 'weighted avg']]
})

categories_df = categories_df.sort_values('F1-Score', ascending=False)

# En iyi ve en kÃ¶tÃ¼ 10 kategori
print("\nâœ… En Ä°yi 10 Kategori (F1-Score):")
print(categories_df.head(10).to_string(index=False))

print("\nâŒ En KÃ¶tÃ¼ 10 Kategori (F1-Score):")
print(categories_df.tail(10).to_string(index=False))

# Grafik
fig, ax = plt.subplots(figsize=(12, 10))
top_bottom = pd.concat([categories_df.head(10), categories_df.tail(10)])
colors = ['green'] * 10 + ['red'] * 10
ax.barh(range(len(top_bottom)), top_bottom['F1-Score'], color=colors, alpha=0.7)
ax.set_yticks(range(len(top_bottom)))
ax.set_yticklabels(top_bottom['Category'])
ax.set_xlabel('F1-Score')
ax.set_title('En Ä°yi ve En KÃ¶tÃ¼ 10 Kategori')
ax.grid(axis='x', alpha=0.3)
plt.tight_layout()
plt.savefig('category_performance.png', dpi=300, bbox_inches='tight')
print("\nâœ… Kategori performans grafiÄŸi kaydedildi: category_performance.png")

# 4. Veri DaÄŸÄ±lÄ±mÄ± Analizi
print("\nğŸ“Š 5. Veri daÄŸÄ±lÄ±mÄ± analizi...")

category_counts = train_df['label'].value_counts()
category_names = [id2label[i] for i in category_counts.index]

plt.figure(figsize=(15, 8))
plt.bar(range(len(category_counts)), category_counts.values, alpha=0.7)
plt.xticks(range(len(category_counts)), category_names, rotation=90)
plt.xlabel('Kategori')
plt.ylabel('Ã–rnek SayÄ±sÄ±')
plt.title('EÄŸitim Setinde Kategori DaÄŸÄ±lÄ±mÄ±')
plt.grid(axis='y', alpha=0.3)
plt.tight_layout()
plt.savefig('data_distribution.png', dpi=300, bbox_inches='tight')
print("âœ… Veri daÄŸÄ±lÄ±mÄ± grafiÄŸi kaydedildi: data_distribution.png")

# 5. En Ã‡ok KarÄ±ÅŸtÄ±rÄ±lan Kategoriler
print("\nğŸ”„ 6. En Ã§ok karÄ±ÅŸtÄ±rÄ±lan kategoriler...")

# Her kategori iÃ§in en Ã§ok hangi kategoriyle karÄ±ÅŸtÄ±rÄ±ldÄ±ÄŸÄ±nÄ± bul
confusion_pairs = []
for i in range(len(cm)):
    for j in range(len(cm)):
        if i != j and cm[i][j] > 0:
            confusion_pairs.append({
                'True': id2label[i],
                'Predicted': id2label[j],
                'Count': cm[i][j]
            })

confusion_df = pd.DataFrame(confusion_pairs).sort_values('Count', ascending=False)

print("\nEn Ã‡ok KarÄ±ÅŸtÄ±rÄ±lan 15 Kategori Ã‡ifti:")
print(confusion_df.head(15).to_string(index=False))

# 6. YanlÄ±ÅŸ Tahminler Analizi
print("\nâŒ 7. YanlÄ±ÅŸ tahmin Ã¶rnekleri...")

wrong_predictions = []
test_texts = test_df.reset_index(drop=True)['text']

for idx, (pred, true) in enumerate(zip(preds, true_labels)):
    if pred != true:
        wrong_predictions.append({
            'Text': test_texts[idx][:100] + '...',
            'True': id2label[true],
            'Predicted': id2label[pred]
        })

wrong_df = pd.DataFrame(wrong_predictions[:20])  # Ä°lk 20 yanlÄ±ÅŸ
print("\nÄ°lk 20 YanlÄ±ÅŸ Tahmin:")
print(wrong_df.to_string(index=False))

# 7. Ã–zet Rapor
print("\n" + "=" * 60)
print("ğŸ“‹ Ã–ZET RAPOR")
print("=" * 60)

final_results = trainer.evaluate()

print(f"\nâœ… Test Accuracy: {final_results['eval_accuracy']:.4f}")
print(f"âœ… Test F1 Score (Weighted): {final_results['eval_f1']:.4f}")
print(f"âœ… Toplam Kategori SayÄ±sÄ±: {num_labels}")
print(f"âœ… Train Ã–rnekleri: {len(train_df)}")
print(f"âœ… Test Ã–rnekleri: {len(test_df)}")
print(f"âœ… Toplam Epoch: {training_args.num_train_epochs}")

# Makro ortalamalar
print(f"\nğŸ“Š Makro Ortalamalar:")
print(f"  Precision: {report['macro avg']['precision']:.4f}")
print(f"  Recall: {report['macro avg']['recall']:.4f}")
print(f"  F1-Score: {report['macro avg']['f1-score']:.4f}")

# Veri dengesizliÄŸi
imbalance_ratio = category_counts.max() / category_counts.min()
print(f"\nâš–ï¸  Veri Dengesizlik OranÄ±: {imbalance_ratio:.2f}x")
print(f"  En fazla Ã¶rnek: {category_counts.max()} ({id2label[category_counts.idxmax()]})")
print(f"  En az Ã¶rnek: {category_counts.min()} ({id2label[category_counts.idxmin()]})")

# 8. TÃ¼m SonuÃ§larÄ± CSV'ye Kaydet
categories_df.to_csv('category_results.csv', index=False)
confusion_df.to_csv('confusion_pairs.csv', index=False)
wrong_df.to_csv('wrong_predictions.csv', index=False)

print("\nâœ… TÃ¼m analizler tamamlandÄ± ve kaydedildi!")
print("\nOluÅŸturulan dosyalar:")
print("  - training_history.png")
print("  - confusion_matrix.png")
print("  - category_performance.png")
print("  - data_distribution.png")
print("  - category_results.csv")
print("  - confusion_pairs.csv")
print("  - wrong_predictions.csv")

print("\nğŸ‰ Rapor hazÄ±r!")

# Model klasÃ¶rÃ¼nÃ¼ zip'le
#!zip - r
#huffpost_model.zip. / huffpost_news_classifier
#!zip - r
#analysis_results.zip *.png *.csv

print("\nğŸ“¦ Model ve analizler zip'lendi:")
print("  - huffpost_model.zip (modeli indirin)")
print("  - analysis_results.zip (grafik ve CSV'leri indirin)")